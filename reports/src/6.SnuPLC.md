---
title: SwiftSnuPL: A Swift/ARM64 version of the SnuPL compiler
author: Sungbin Jo (2021-13630), Kijun Shin (2021-15391)
---

## Introduction

We have rewrote the SnuPL compiler in the Swift language.

### Motivation

The unfamiliarity on the C++ language pushed us to experiment with
porting the compiler to a more familiar language.

Partially porting the parser to Swift showed a significant
productivity increase not only from familiarity but also from the
conciseness of the language, algebric data types, and pattern
matching.

We decided to use the Swift port as a sandbox for experimenting with
various design deviations from the original design.

### Design Goals

The following were the goals when starting the rewrite:

- Each phase has a component that is responsible for it.
- These components must communicate with plain data structures that do
  not have any behavioral knowledge of phases.
- To report multiple errors, each phase tries hard enough to make
  something, with a list of encountered errors.

While these goals were not totally achieved, we believe that

### Data Structures

The tokens

### Known Problems / Possible Improvements

The biggest known problem is that the `Resolver` does not do any error
handling in its current form. While the appropriate functions are
marked throwing, and basically.

## Syntax Analysis

The parser is a simple LL(1) parser.

## Phase 3: Semantic Analysis

The `Resolver` of SwiftSnuPL has two responsibilities:

- Resolving the tokens to the appropriate symbols
- Calculating the types of various expressions

Notably, instead of the parser resolving the symbols during parsing,
we handle symbol resolving in phase 3.

As SwiftSnuPL has static scoping rules, the notion of scopes do not
have to exist outside of the `Resolver`; it maintains an internal
stack of scopes during resolving, and the scopes do not have any
presence after this phase.

Scopes contain multiple `Symbol`s,

To support `const` symbols, the `Resolver` implements a simple
compile-time evaluator. Since the `Parser` only allows a separate

SwiftSnuPL also completes phase 3. The SwiftSnuPL Resolver handles
both symbol resolving and type checking, covering a subset of phase 2
and phase 3. The Resolver saves type and symbol information on an side
table separately from the parser AST. This not only allows the parser
to continue and parse the code, and report resolver errors in a batch,
but also allows centralizing resolving and type checking logic. The
resolver finally produces a map of AST nodes to type information and
resolved Symbols.


## Phase 4: Intermediate Code Generation

The Swift `Generator` converts a parsed module with resolver
information to the IR, which is basically two dictionaries; a
symbol-to-instructions mapping that represents the TEXT section, and a
symbol-to-strings mapping that represents the DATA section.

The IR is almost the same with the provided CppSnuPL TAC;

`Operand` represents 64-bit scalar values that can either be a
constant, a register value, or a value on the stack. Stack allocations
are represented as pointers as well. Only the `.symbol` and
`.temporary` cases are modifiable; others are constant operands.

We did not model this distinction as separate types for brevity;
though we could have separate types for mutable operands and constant
operands, and declare the IR more strictly.

```swift
enum Operand: Equatable, Hashable {
    case constant(Int64)
    case temporary(name: String)
    case string(name: String)
    case allocation(name: String)
    case symbol(Resolver.Symbol)
}
```

The IR is modeled as below:

```swift
enum Instruction {
    case move(destination: Operand, source: Operand)
    case unary(op: UnaryOp, destination: Operand, source: Operand)
    case binary(op: BinaryOp, destination: Operand, source1: Operand, source2: Operand)
    case parameter(destination: Operand, index: Int)

    case jump(destination: String)
    case branch(destination: String, source1: Operand, source2: Operand)  // branch if equal
    case call(destination: Operand?, symbol: Resolver.Symbol, arguments: [Operand])
    case `return`(value: Operand?)

    case load(destination: Operand, source: Operand, size: MemorySize)
    case store(source: Operand, destination: Operand, size: MemorySize)

    case label(name: String)
}
```

The compilation to the IR is quite straightforward;

Some interesting decisions for such features:

To allow passing subarrays between functions, the binary layout of
arrays are changed. Each array has a 8-byte header, consisting of two
4-byte little-endian integer values representing 1) the size of all
items (e.g. the size of items multiplied by the count of items), and
2) the size of one item. Nested arrays gets a nested layout.

This implementation allows arrays to be nested, and DIM can be
implemented as N-dimensional arrays get to have 8N bytes allocated as
a header, so calculating the length of the k-th dimension becomes
dividing the integer between the 2k-th integer and 2k+1-th integer.

Another advantage of the item size header is that we can dynamically
select store/load instructions, allowing for example passing integer
arrays to longint arrays, or vice versa.

This unfortunately means that storing an item to the array requires
two memory reads and a branch, which is probably quite detrimental to
performance. Thankfully weâ€™re not concerned on performance at this
stage, so this working well is enough for us.

Another interesting tidbit is that we allocate the array on the stack,
even if the symbol for the array is global; due to how we do not give
any distinction between local arrays and passed arrays, all variables
typed array is basically just a pointer, even in the case where the
array was declared locally. In this case, it is the pointer to the
stack allocation that becomes a global symbol.
