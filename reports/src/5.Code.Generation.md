---
title: Code Generation
author: Sungbin Jo (2021-13630), Kijun Shin (2021-15391)
---

## SwiftSnuPL code generation implementation notes

The SwiftSnuPL compiler only supports the target triple
`aarch64-linux-gnu`. Notably, the generated code uses a Linux ABI,
with little endian semantics. For other platforms, linking to the
aarch64 libc and running the resulting binary with user mode qemu is
recommended. Detailed instructions for running binaries are noted
below.

The SwiftSnuPL compiler uses a very simplistic model where every
operand gets allocated a separate stack space, without any
optimization attempts. Each IR instruction gets compiled to loads from
the stack, a few aarch64 instructions that corresponds to the IR, and
stores to the stack.

Because this is so simplistic, implementing itself is a breeze, with
the checks for cases where immediate values donâ€™t fit in the
instruction, and needs separate checks. There are quite a few
shortcomings on this model: the biggest one is that successive
operations operating on the same operand compiles to successive stores
and loads on the same memory location. Properly fixing this problem
would require some kind of register allocation scheme; a much
simplistic approach could aim at least optimize useless loads by
peeking the previous instruction and checking if an operand we needs
already exists in a register, and optimizing the load into a move.

We have a version of this patch implemented, but due to correctness
concerns, it is disabled by default.

Another would be that the compiler allocates every operand separately
on the stack; this results in using a lot of stack space. A proper
solution here would be doing some sort of liveness analysis on the IR,
and allocating the same place on the stack. Unfortunately we could not
implement this due to time constraints; we were hopefully out of
schedule and had to aim the quickest path to completion.

Overall, the assembly generation part of the compiler was

### Architecture

The code generator receives four inputs, as shown below:

```swift
class AssemblyGenerator {
    var instructions: [Resolver.Symbol: [IRGenerator.Instruction]]
    var allocations: [String: Int64]
    var stringLiterals: [String: [UInt8]]
    var globalVariables: Set<String>
}
```

The dictionary `instructions` is the direct output of the IR
generator. Especially they are main module, or procedure/function.
General variables aren't contained directly, but it will be accessed
when loop through main module/procedure/function instructions.
`allocations` used to calculate size of some operands(IR).
`stringLiterals` used to embed string literals on data section. Since
string is not special type in SnuPL/2(it's just array of char), so
embedding has to satisfy middleware structure of array.
`globalVariables` used to get name of global variables, which are
required to generate label in data section of assembly code. Each
global variables get 8-byte space, and it is marked with label. If we
implements nested function call, then global variables can be
generalized as variables defined on starting point of nested call, so
`globalVariables` won't needed. However it requires complex methods
such as 'Access links', so we choose these implementation methods for
simplicity.


Structure of assembly codes are related to binary file format. It
starts with text section, where generated assembly code will
placed. After that, data section located. We allocate space for global
variables and string literals in here.
```swift
func generate() -> String {
    var assembly = """
        \t.text
        \(instructions.map(generate(symbol:instructions:)).joined(separator: "\n"))
        \t.data\n
        """
    for globalVariable in globalVariables { assembly += "\t.comm \(globalVariable),8\n" }
    for (key, value) in stringLiterals {
        assembly += """
            \(key):
            \t.word \(value.count + 1)
            \t.word 1\n
            """
        for char in value { assembly += "\t.byte \(char)\n" }
        assembly += "\t.byte 0\n"
    }
    return assembly
}
```

For each symbol contained in `instructions` - main, procedure,
function - they generate assembly code from their interal part, so we
can just append it consecutively. Each code generation logic starts
with calculating stack size to fully accept every operands in
procedure/function. Then every operands can get their unique positions
in stack memory. We will save this information in `stackMapping`
dictionary. Note that we set `stackSize` as multiple of 16, the
condition of arm64 ABI.
```swift
func generate(symbol: Resolver.Symbol, instructions: [IRGenerator.Instruction]) -> String {
    let operands = operands(in: instructions)
    var stackMapping: [IRGenerator.Operand: Int64] = [:]
    var stackSize: Int64 = 0
    for operand in operands {
        let size = size(of: operand)
        stackMapping[operand] = stackSize
        stackSize += size
    }
    if stackSize % 16 != 0 { stackSize += 16 - (stackSize % 16) }
    // assembly code generation...
```


#### Helper Functions

- Immediate Value Embedding
There are many places that needs immediate value in assembly
code. However, compile target is 64-bit but instructions have 32-bit
length format, which makes generating assembly code about immediate
value become very long. We made this process as functions.

```swift
func embedImm(imm: Int64, scratch scratchRegister: String) -> String {
    if imm < 0 {
        return """
            \tmov \(scratchRegister), #\(imm % (1 << 16))
            \tmovk \(scratchRegister), #\((imm >> 16) % (1 << 16)), LSL 16
            \tmovk \(scratchRegister), #\((imm >> 32) % (1 << 16)), LSL 32
            \tmovk \(scratchRegister), #\((imm >> 48) % (1 << 16)), LSL 48
            """
    } else {
        var retasm = "\tmov \(scratchRegister), #\(imm % (1 << 16))\n"
        if imm >= (1 << 16) { retasm += "\tmovk \(scratchRegister), #\((imm >> 16) % (1 << 16)), LSL 16\n" }
        if imm >= (1 << 32) { retasm += "\tmovk \(scratchRegister), #\((imm >> 32) % (1 << 16)), LSL 32\n" }
        if imm >= (1 << 48) { retasm += "\tmovk \(scratchRegister), #\((imm >> 48) % (1 << 16)), LSL 48\n" }
        return retasm
    }
}
```
It also helps to generate essential parts of number bits, too.

- Load and Store Operands

Our simplistic assembly generation model of compiler's core logic is
implemented as helper function `withOperands`. Every operands are
loaded and stored after `body` assembly executed. This function gets
arguments as `load`, `to`, `store`, `from`, `body`. When symbols are
global variables, it loads the value of variables from predefined data
section instead of registers. Also it gets `scratch` to calculate some
address informations on `scratchRegister`, which caller knows it
doesn't affect any other execution. `offset` are needed to calculate
accurate stack memory address when sp is changed by several reason.
For example, to embed function arguments which their index is larger
than 8, stack has to be expanded before writing arguments according to
arm64 ABI.

```swift
func withOperands(
    load sourceOperands: [IRGenerator.Operand] = [], to sourceRegisters: [String] = [],
    store destinationOperands: [IRGenerator.Operand] = [], from destinationRegisters: [String] = [],
    scratch scratchRegister: String, offset stackExpanded: Int64 = 0, body: (() -> String)? = nil
) -> String {
    guard !sourceRegisters.contains(scratchRegister) && !destinationRegisters.contains(scratchRegister) else {
        fatalError()
    }
    guard sourceOperands.count == sourceRegisters.count else { fatalError() }
    guard destinationOperands.count == destinationRegisters.count else { fatalError() }
    var assembly = ""
    for (operand, register) in zip(sourceOperands, sourceRegisters) {
        switch operand {
        case .symbol(let symbol):
            let stackOffset = stackMapping[operand]! + stackExpanded
            if symbol.isGlobal {
                assembly += """
                    \tadrp \(register), \(symbol.token.string)
                    \tadd \(register), \(register), :lo12:\(symbol.token.string)
                    \tldr \(register), [\(register)] // \(symbol.token.string)\n
                    """
            } else {
                if stackOffset < 256 {
                    assembly += "\tldr \(register), [sp, #\(stackOffset)] // \(operand)\n"
                } else if stackOffset < 4096 {
                    assembly += """
                        \tadd \(register), sp, #\(stackOffset)
                        \tldr \(register), [\(register)] // \(operand)\n
                        """
                } else {
                    assembly += embedImm(imm: stackOffset, scratch: "x15");
                    assembly += """
                        \tadd \(register), sp, x15
                        \tldr \(register), [\(register)] // \(operand)\n
                        """
                }
            }
        // case by case
        }
    }
    if let body = body { assembly += body() }
    for (operand, register) in zip(destinationOperands, destinationRegisters) {
        switch operand {
        // case by case
        }
    }
    return assembly
}
```

It is worth to note branch condition of `stackOffset`. It is related
to arm64's immediate value range according to instruction type. To
make optimized assembly code, by checking small range candidates,
change format of instructions.

- Get List of Every Operands in Procedure/Function
Procedure/Function has instruction list made by middleware. By loop
through it, controlling case by case, set of operands are made like
this:
```swift
func operands(in instruction: IRGenerator.Instruction) -> Set<IRGenerator.Operand> {
    switch instruction {
    case .move(let destination, let source), .unary(_, let destination, let source): return [source, destination]
    case .binary(_, let destination, let source1, let source2): return [source1, source2, destination]
    case .parameter(let destination, _): return [destination]
    case .jump: return []
    case .branch(_, let source1, let source2): return [source1, source2]
    case .call(let destination, _, let arguments):
        var operands: Set<IRGenerator.Operand> = []
        for argument in arguments { operands.insert(argument) }
        if let destination = destination { operands.insert(destination) }
        return operands
    case .return(let value): if let value = value { return [value] } else { return [] }
    case .load(let destination, let source, _), .store(let source, let destination, _):
        return [source, destination]
    case .label: return []
    }
}
```


### Cross-compiling `aarch64-linux-gnu` code in x86_64 environments

For building, `binutils` for assembling and linking, and `libc` for
the `aarch64-linux-gnu` target triple is required.

The easiest way for running the produced binaries is by running them
with QEMU user mode.

Assuming an Ubuntu 20.04 environment, the following commands produce
an `aarch64-linux-gnu` binary and run it with `qemu-user`.

```shellsession
$ # Install required packages
$ sudo apt-get install binutils-aarch64-linux-gnu libc-dev-arm64-cross
$
$ # Compile, assemble, and link the binary
$ ./SwiftSnuPL compile -S main.mod > main.s
$ ./SwiftSnuPL stdlib -S > libSnuPL.s
$ aarch64-linux-gnu-as -o main.o main.s
$ aarch64-linux-gnu-as -o libSnuPL.o libSnuPL.s
$ aarch64-linux-gnu-ld -o main \
  -dynamic-linker /lib/ld-linux-aarch64.so.1 \
  /usr/aarch64-linux-gnu/lib/crt1.o \
  /usr/aarch64-linux-gnu/lib/crti.o \
  -lc libSnuPL.o main.o \
  /usr/aarch64-linux-gnu/lib/crtn.o
$
$ # Run the binary with QEMU user mode
$ qemu-aarch64 -L /usr/aarch64-linux-gnu ./main
```
